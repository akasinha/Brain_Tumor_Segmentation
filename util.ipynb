{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "util.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md-DZ9DY3ZUM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "3abbcc2c-1647-4bf1-c905-7fe27120531b"
      },
      "source": [
        "import cv2\n",
        "import h5py\n",
        "import imageio\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython.display import Image\n",
        "from keras import backend as K\n",
        "from tensorflow.keras import Input, Model\n",
        "from tf.keras.layers import (\n",
        "    Activation,\n",
        "    Conv3D,\n",
        "    Deconvolution3D,\n",
        "    MaxPooling3D,\n",
        "    UpSampling3D,\n",
        ")\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.compat.v1.logging import INFO, set_verbosity\n",
        "\n",
        "set_verbosity(INFO)\n",
        "\n",
        "K.set_image_data_format(\"channels_first\")\n",
        "\n",
        "\n",
        "def plot_image_grid(image):\n",
        "    data_all = []\n",
        "\n",
        "    data_all.append(image)\n",
        "\n",
        "    fig, ax = plt.subplots(3, 6, figsize=[16, 9])\n",
        "\n",
        "    # coronal plane\n",
        "    coronal = np.transpose(data_all, [1, 3, 2, 4, 0])\n",
        "    coronal = np.rot90(coronal, 1)\n",
        "\n",
        "    # transversal plane\n",
        "    transversal = np.transpose(data_all, [2, 1, 3, 4, 0])\n",
        "    transversal = np.rot90(transversal, 2)\n",
        "\n",
        "    # sagittal plane\n",
        "    sagittal = np.transpose(data_all, [2, 3, 1, 4, 0])\n",
        "    sagittal = np.rot90(sagittal, 1)\n",
        "\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(coronal.shape[2])\n",
        "        ax[0][i].imshow(np.squeeze(coronal[:, :, n, :]))\n",
        "        ax[0][i].set_xticks([])\n",
        "        ax[0][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[0][i].set_ylabel('Coronal', fontsize=15)\n",
        "\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(transversal.shape[2])\n",
        "        ax[1][i].imshow(np.squeeze(transversal[:, :, n, :]))\n",
        "        ax[1][i].set_xticks([])\n",
        "        ax[1][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[1][i].set_ylabel('Transversal', fontsize=15)\n",
        "\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(sagittal.shape[2])\n",
        "        ax[2][i].imshow(np.squeeze(sagittal[:, :, n, :]))\n",
        "        ax[2][i].set_xticks([])\n",
        "        ax[2][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[2][i].set_ylabel('Sagittal', fontsize=15)\n",
        "\n",
        "    fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "\n",
        "def visualize_data_gif(data_):\n",
        "    images = []\n",
        "    for i in range(data_.shape[0]):\n",
        "        x = data_[min(i, data_.shape[0] - 1), :, :]\n",
        "        y = data_[:, min(i, data_.shape[1] - 1), :]\n",
        "        z = data_[:, :, min(i, data_.shape[2] - 1)]\n",
        "        img = np.concatenate((x, y, z), axis=1)\n",
        "        images.append(img)\n",
        "    imageio.mimsave(\"/tmp/gif.gif\", images, duration=0.01)\n",
        "    return Image(filename=\"/tmp/gif.gif\", format='png')\n",
        "\n",
        "\n",
        "# Some code was borrowed from:\n",
        "# https://github.com/ellisdg/3DUnetCNN/blob/master/unet3d/\n",
        "\n",
        "\n",
        "def create_convolution_block(input_layer, n_filters, batch_normalization=False,\n",
        "                             kernel=(3, 3, 3), activation=None,\n",
        "                             padding='same', strides=(1, 1, 1),\n",
        "                             instance_normalization=False):\n",
        "    \n",
        "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(\n",
        "        input_layer)\n",
        "    if activation is None:\n",
        "        return Activation('relu')(layer)\n",
        "    else:\n",
        "        return activation()(layer)\n",
        "\n",
        "\n",
        "def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2),\n",
        "                       strides=(2, 2, 2),\n",
        "                       deconvolution=False):\n",
        "    if deconvolution:\n",
        "        return Deconvolution3D(filters=n_filters, kernel_size=kernel_size,\n",
        "                               strides=strides)\n",
        "    else:\n",
        "        return UpSampling3D(size=pool_size)\n",
        "\n",
        "\n",
        "def unet_model_3d(loss_function, input_shape=(4, 160, 160, 16),\n",
        "                  pool_size=(2, 2, 2), n_labels=3,\n",
        "                  initial_learning_rate=0.00001,\n",
        "                  deconvolution=False, depth=4, n_base_filters=32,\n",
        "                  include_label_wise_dice_coefficients=False, metrics=[],\n",
        "                  batch_normalization=False, activation_name=\"sigmoid\"):\n",
        "   \n",
        "    inputs = Input(input_shape)\n",
        "    current_layer = inputs\n",
        "    levels = list()\n",
        "\n",
        "    # add levels with max pooling\n",
        "    for layer_depth in range(depth):\n",
        "        layer1 = create_convolution_block(input_layer=current_layer,\n",
        "                                          n_filters=n_base_filters * (\n",
        "                                                  2 ** layer_depth),\n",
        "                                          batch_normalization=batch_normalization)\n",
        "        layer2 = create_convolution_block(input_layer=layer1,\n",
        "                                          n_filters=n_base_filters * (\n",
        "                                                  2 ** layer_depth) * 2,\n",
        "                                          batch_normalization=batch_normalization)\n",
        "        if layer_depth < depth - 1:\n",
        "            current_layer = MaxPooling3D(pool_size=pool_size)(layer2)\n",
        "            levels.append([layer1, layer2, current_layer])\n",
        "        else:\n",
        "            current_layer = layer2\n",
        "            levels.append([layer1, layer2])\n",
        "\n",
        "    # add levels with up-convolution or up-sampling\n",
        "    for layer_depth in range(depth - 2, -1, -1):\n",
        "        up_convolution = get_up_convolution(pool_size=pool_size,\n",
        "                                            deconvolution=deconvolution,\n",
        "                                            n_filters=\n",
        "                                            current_layer._keras_shape[1])(\n",
        "            current_layer)\n",
        "        concat = concatenate([up_convolution, levels[layer_depth][1]], axis=1)\n",
        "        current_layer = create_convolution_block(\n",
        "            n_filters=levels[layer_depth][1]._keras_shape[1],\n",
        "            input_layer=concat, batch_normalization=batch_normalization)\n",
        "        current_layer = create_convolution_block(\n",
        "            n_filters=levels[layer_depth][1]._keras_shape[1],\n",
        "            input_layer=current_layer,\n",
        "            batch_normalization=batch_normalization)\n",
        "\n",
        "    final_convolution = Conv3D(n_labels, (1, 1, 1))(current_layer)\n",
        "    act = Activation(activation_name)(final_convolution)\n",
        "    model = Model(inputs=inputs, outputs=act)\n",
        "\n",
        "    if not isinstance(metrics, list):\n",
        "        metrics = [metrics]\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=initial_learning_rate), loss=loss_function,\n",
        "                  metrics=metrics)\n",
        "    return model\n",
        "\n",
        "\n",
        "def visualize_patch(X, y):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=[10, 5], squeeze=False)\n",
        "\n",
        "    ax[0][0].imshow(X[:, :, 0], cmap='Greys_r')\n",
        "    ax[0][0].set_yticks([])\n",
        "    ax[0][0].set_xticks([])\n",
        "    ax[0][1].imshow(y[:, :, 0], cmap='Greys_r')\n",
        "    ax[0][1].set_xticks([])\n",
        "    ax[0][1].set_yticks([])\n",
        "\n",
        "    fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "\n",
        "class VolumeDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self,\n",
        "                 sample_list,\n",
        "                 base_dir,\n",
        "                 batch_size=1,\n",
        "                 shuffle=True,\n",
        "                 dim=(160, 160, 16),\n",
        "                 num_channels=4,\n",
        "                 num_classes=3,\n",
        "                 verbose=1):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.base_dir = base_dir\n",
        "        self.dim = dim\n",
        "        self.num_channels = num_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.verbose = verbose\n",
        "        self.sample_list = sample_list\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.sample_list))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.sample_list) / self.batch_size))\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples'\n",
        "\n",
        "       \n",
        "        X = np.zeros((self.batch_size, self.num_channels, *self.dim),\n",
        "                     dtype=np.float64)\n",
        "        y = np.zeros((self.batch_size, self.num_classes, *self.dim),\n",
        "                     dtype=np.float64)\n",
        "\n",
        "        \n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            \n",
        "            if self.verbose == 1:\n",
        "                print(\"Training on: %s\" % self.base_dir + ID)\n",
        "            with h5py.File(self.base_dir + ID, 'r') as f:\n",
        "                X[i] = np.array(f.get(\"x\"))\n",
        "                \n",
        "                y[i] = np.moveaxis(np.array(f.get(\"y\")), 3, 0)[1:]\n",
        "        return X, y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        \n",
        "        indexes = self.indexes[\n",
        "                  index * self.batch_size: (index + 1) * self.batch_size]\n",
        "        \n",
        "        sample_list_temp = [self.sample_list[k] for k in indexes]\n",
        "        \n",
        "        X, y = self.__data_generation(sample_list_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "def get_labeled_image(image, label, is_categorical=False):\n",
        "    if not is_categorical:\n",
        "        label = to_categorical(label, num_classes=4).astype(np.uint8)\n",
        "\n",
        "    image = cv2.normalize(image[:, :, :, 0], None, alpha=0, beta=255,\n",
        "                          norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F).astype(\n",
        "        np.uint8)\n",
        "\n",
        "    labeled_image = np.zeros_like(label[:, :, :, 1:])\n",
        "\n",
        "    # remove tumor part from image\n",
        "    labeled_image[:, :, :, 0] = image * (label[:, :, :, 0])\n",
        "    labeled_image[:, :, :, 1] = image * (label[:, :, :, 0])\n",
        "    labeled_image[:, :, :, 2] = image * (label[:, :, :, 0])\n",
        "\n",
        "    # color labels\n",
        "    labeled_image += label[:, :, :, 1:] * 255\n",
        "    return labeled_image\n",
        "\n",
        "\n",
        "def predict_and_viz(image, label, model, threshold, loc=(100, 100, 50)):\n",
        "    image_labeled = get_labeled_image(image.copy(), label.copy())\n",
        "\n",
        "    model_label = np.zeros([3, 320, 320, 160])\n",
        "\n",
        "    for x in range(0, image.shape[0], 160):\n",
        "        for y in range(0, image.shape[1], 160):\n",
        "            for z in range(0, image.shape[2], 16):\n",
        "                patch = np.zeros([4, 160, 160, 16])\n",
        "                p = np.moveaxis(image[x: x + 160, y: y + 160, z:z + 16], 3, 0)\n",
        "                patch[:, 0:p.shape[1], 0:p.shape[2], 0:p.shape[3]] = p\n",
        "                pred = model.predict(np.expand_dims(patch, 0))\n",
        "                model_label[:, x:x + p.shape[1],\n",
        "                y:y + p.shape[2],\n",
        "                z: z + p.shape[3]] += pred[0][:, :p.shape[1], :p.shape[2],\n",
        "                                      :p.shape[3]]\n",
        "\n",
        "    model_label = np.moveaxis(model_label[:, 0:240, 0:240, 0:155], 0, 3)\n",
        "    model_label_reformatted = np.zeros((240, 240, 155, 4))\n",
        "\n",
        "    model_label_reformatted = to_categorical(label, num_classes=4).astype(\n",
        "        np.uint8)\n",
        "\n",
        "    model_label_reformatted[:, :, :, 1:4] = model_label\n",
        "\n",
        "    model_labeled_image = get_labeled_image(image, model_label_reformatted,\n",
        "                                            is_categorical=True)\n",
        "\n",
        "    fig, ax = plt.subplots(2, 3, figsize=[10, 7])\n",
        "\n",
        "    \n",
        "    x, y, z = loc\n",
        "\n",
        "    ax[0][0].imshow(np.rot90(image_labeled[x, :, :, :]))\n",
        "    ax[0][0].set_ylabel('Ground Truth', fontsize=15)\n",
        "    ax[0][0].set_xlabel('Sagital', fontsize=15)\n",
        "\n",
        "    ax[0][1].imshow(np.rot90(image_labeled[:, y, :, :]))\n",
        "    ax[0][1].set_xlabel('Coronal', fontsize=15)\n",
        "\n",
        "    ax[0][2].imshow(np.squeeze(image_labeled[:, :, z, :]))\n",
        "    ax[0][2].set_xlabel('Transversal', fontsize=15)\n",
        "\n",
        "    ax[1][0].imshow(np.rot90(model_labeled_image[x, :, :, :]))\n",
        "    ax[1][0].set_ylabel('Prediction', fontsize=15)\n",
        "\n",
        "    ax[1][1].imshow(np.rot90(model_labeled_image[:, y, :, :]))\n",
        "    ax[1][2].imshow(model_labeled_image[:, :, z, :])\n",
        "\n",
        "    fig.subplots_adjust(wspace=0, hspace=.12)\n",
        "\n",
        "    for i in range(2):\n",
        "        for j in range(3):\n",
        "            ax[i][j].set_xticks([])\n",
        "            ax[i][j].set_yticks([])\n",
        "\n",
        "    return model_label_reformatted\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-196b984b84c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from tf.keras.layers import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mConv3D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}